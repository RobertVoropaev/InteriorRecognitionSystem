{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Система распознавания предметов интерьера в потоковом видео\n",
    "## Часть 6: Сбор статистики по площади, занимаемой объектом на кадре\n",
    "### Воропаев Роберт, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части проводится сбор статистики средней площади занимаемой объектами разных классов на изображениях датасета. Позже эта информация будет использована для определения порога показа маски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class def_config:\n",
    "\n",
    "    main_data_dir = \"data/ADE20K_encoded/\"\n",
    "    callbacks_dir = \"callbacks/\"\n",
    "\n",
    "    img_shape = 256\n",
    "    classes_num = 17\n",
    "\n",
    "    batch_size = 4\n",
    "    epoch_num = 1\n",
    "    train_coef = 0.001\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    last_activation = \"sigmoid\"\n",
    "    loss_function = \"categorical_crossentropy\"\n",
    "\n",
    "    gpu_memory_limit = 0.8\n",
    "    cpu_threads_num = 2\n",
    "\n",
    "    callbacks_monitor = \"val_jaccard_coef\"\n",
    "    callbacks_data_format = \"%m.%d_%H-%M\"\n",
    "    file_name = \"DefName\"\n",
    "    \n",
    "    is_load = False\n",
    "    weight_path = None\n",
    "    \n",
    "    argparse_is_on = False\n",
    "    \n",
    "    \n",
    "args = def_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# System\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Base\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Activation, Input\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import Dropout, BatchNormalization, Concatenate\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "# Preprocessing\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# Backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Seed\n",
    "seed = 99\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "from scripts_.PathFinder import PathFinder\n",
    "from scripts_.SegEncoder import SegEncoder\n",
    "from scripts_.ClassList import ClassList\n",
    "\n",
    "pf = PathFinder()\n",
    "cl = ClassList(load_class_encode=True, class_encode_path=\"static/class_encode.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_dir = args.main_data_dir\n",
    "\n",
    "train_dir = main_data_dir + \"train/\"\n",
    "val_dir = main_data_dir + \"val/\"\n",
    "\n",
    "img_train_dir = train_dir + \"img/\"\n",
    "mask_train_dir = train_dir + \"mask/\"\n",
    "\n",
    "img_val_dir = val_dir + \"img/\"\n",
    "mask_val_dir = val_dir + \"mask/\"\n",
    "\n",
    "train_size = len(os.listdir(path=train_dir + \"img/\"))\n",
    "val_size = len(os.listdir(path=val_dir + \"img/\"))\n",
    "\n",
    "img_shape = args.img_shape\n",
    "batch_size = args.batch_size\n",
    "classes_num = args.classes_num\n",
    "\n",
    "epoch_num = args.epoch_num\n",
    "train_coef = args.train_coef\n",
    "learning_rate = args.learning_rate\n",
    "\n",
    "loss_function = args.loss_function\n",
    "last_activation = args.last_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 s, sys: 82.3 ms, total: 44 s\n",
      "Wall time: 43.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "area_dict = {i : [] for i in range(0, classes_num)}\n",
    "for file, path in pf.data_gen(mask_train_dir, return_path=True):\n",
    "    train_mask = cv2.imread(path + \"/\" + file, cv2.IMREAD_GRAYSCALE)\n",
    "    train_mask = cv2.resize(train_mask, (img_shape, img_shape), interpolation=cv2.INTER_NEAREST)\n",
    "    train_mask = train_mask.reshape(img_shape, img_shape, 1)\n",
    "    train_mask = to_categorical(train_mask, num_classes=classes_num)\n",
    "    for channel in range(0, classes_num):\n",
    "        if train_mask[:, :, channel].sum() != 0:\n",
    "            area_dict[channel].append(train_mask[:, :, channel].sum() / img_shape**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"static/class_areas.txt\", \"w\") as f:\n",
    "    for i in range(classes_num):\n",
    "        f.write(str(i) + '\\t' + str(np.average(np.array(area_dict[i]))) + \"\\t\" + str(cl.class_list[i]) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
