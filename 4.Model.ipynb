{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка системы распознавания предметов интерьера в потоковом видео\n",
    "## Часть 4: Нейронная сеть для сегментации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class def_config:\n",
    "\n",
    "    main_data_dir = \"data/ADE20K_encoded/\"\n",
    "    callbacks_dir = \"callbacks/\"\n",
    "\n",
    "    img_shape = 256\n",
    "    classes_num = 31\n",
    "\n",
    "    batch_size = 4\n",
    "    epoch_num = 1\n",
    "    train_coef = 0.001\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    last_activation = \"sigmoid\"\n",
    "    loss_function = \"categorical_crossentropy\"\n",
    "\n",
    "    gpu_memory_limit = 0.8\n",
    "    cpu_threads_num = 2\n",
    "\n",
    "    callbacks_monitor = \"val_jaccard_coef\"\n",
    "    callbacks_data_format = \"%m.%d_%H-%M\"\n",
    "    file_name = \"DefName\"\n",
    "    \n",
    "    is_load = False\n",
    "    argparse_is_on = False\n",
    "    \n",
    "    \n",
    "args = def_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Base\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Activation, Input\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import Dropout, BatchNormalization, Concatenate\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "# Preprocessing\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# Backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Seed\n",
    "seed = 99\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3389050060\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7745919428908242910\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=args.cpu_threads_num,\n",
    "                        inter_op_parallelism_threads=args.cpu_threads_num)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = args.gpu_memory_limit\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# GPU check list\n",
    "GPU_list = [x for x in device_lib.list_local_devices() \n",
    "            if x.device_type == 'GPU' or x.device_type == \"GPU\"]\n",
    "print(GPU_list)\n",
    "\n",
    "if not tf.test.is_gpu_available():\n",
    "    raise OSError(\"GPU not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Настройки сегментации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим папки с изображениями и масками для обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_dir = args.main_data_dir\n",
    "\n",
    "train_dir = main_data_dir + \"train/\"\n",
    "val_dir = main_data_dir + \"val/\"\n",
    "\n",
    "img_train_dir = train_dir + \"img/\"\n",
    "mask_train_dir = train_dir + \"mask/\"\n",
    "\n",
    "img_val_dir = val_dir + \"img/\"\n",
    "mask_val_dir = val_dir + \"mask/\"\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "if def_config.argparse_is_on:\n",
    "    file_name = sys.argv[0].split(\".\")[-2]\n",
    "else:\n",
    "    file_name = def_config.file_name\n",
    "callbacks_dir = args.callbacks_dir\n",
    "\n",
    "try:\n",
    "    os.mkdir(callbacks_dir)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "callbacks_dir_name = file_name + now.strftime(\"_\" + def_config.callbacks_data_format) + \"/\"\n",
    "\n",
    "callbacks_full_dir = callbacks_dir + callbacks_dir_name\n",
    "try:\n",
    "    os.mkdir(callbacks_full_dir)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер обучающей и валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6522\n",
      "Val size: 644\n"
     ]
    }
   ],
   "source": [
    "train_size = len(os.listdir(path=train_dir + \"img/\"))\n",
    "val_size = len(os.listdir(path=val_dir + \"img/\"))\n",
    "print(\"Train size: \" + str(train_size))\n",
    "print(\"Val size: \" + str(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроки нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = args.img_shape\n",
    "batch_size = args.batch_size\n",
    "classes_num = args.classes_num\n",
    "\n",
    "epoch_num = args.epoch_num\n",
    "train_coef = args.train_coef\n",
    "learning_rate = args.learning_rate\n",
    "\n",
    "loss_function = args.loss_function\n",
    "last_activation = args.last_activation\n",
    "\n",
    "is_load = args.is_load\n",
    "if is_load:\n",
    "    weight_path = args.weight_path\n",
    "else:\n",
    "    weight_path = None\n",
    "\n",
    "\n",
    "with open(callbacks_dir + callbacks_dir_name + \"/\" + \"config.txt\", \"w\") as f:\n",
    "    if def_config.argparse_is_on:\n",
    "        args_str = str(args).lstrip(\"Namespace(\").rstrip(')')\n",
    "        args_arr = args_str.split(\", \")\n",
    "        f.write(\"\\n\".join(args_arr))\n",
    "    else:\n",
    "        f.write(\"Def_config\\n\")\n",
    "\n",
    "callbacks_monitor = args.callbacks_monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент Дайса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + smooth) / \n",
    "            (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент Джакарда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / \n",
    "            (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss-функции "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def jaccard_loss(y_true, y_pred):\n",
    "    return 1 - jaccard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Генератор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(img_dir, mask_dir, classes_num, batch_size):\n",
    "    img_folder = img_dir\n",
    "    mask_folder = mask_dir\n",
    "\n",
    "    img_list = os.listdir(img_folder)\n",
    "    random.shuffle(img_list)\n",
    "    img_dir_size = len(img_list)\n",
    "\n",
    "    for i in range(len(img_list)):\n",
    "        img_list[i] = img_list[i].split(\".\")[0]  # отделяем имя от формата\n",
    "\n",
    "    counter = 0\n",
    "    while (True):\n",
    "        img = np.zeros((batch_size, img_shape, img_shape, 3)).astype('float')\n",
    "        mask = np.zeros((batch_size, img_shape, img_shape, classes_num)).astype(\"uint8\")\n",
    "\n",
    "        for i in range(counter, counter + batch_size):\n",
    "            train_img = cv2.imread(img_folder + '/' + img_list[i] + \".jpg\") / 255.\n",
    "            train_img = cv2.resize(train_img, (img_shape, img_shape))\n",
    "\n",
    "            img[i - counter] = train_img\n",
    "\n",
    "            train_mask = cv2.imread(mask_folder + '/' + img_list[i] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "            train_mask = cv2.resize(train_mask, (img_shape, img_shape), interpolation=cv2.INTER_NEAREST)\n",
    "            train_mask = train_mask.reshape(img_shape, img_shape, 1)\n",
    "            train_mask = to_categorical(train_mask, num_classes=classes_num)\n",
    "\n",
    "            mask[i - counter] = train_mask\n",
    "\n",
    "        counter += batch_size\n",
    "\n",
    "        if counter + batch_size >= img_dir_size:\n",
    "            counter = 0\n",
    "            random.shuffle(img_list)\n",
    "\n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "train_gen = data_gen(img_train_dir, mask_train_dir, classes_num=classes_num, batch_size=batch_size)\n",
    "val_gen = data_gen(img_val_dir, mask_val_dir, classes_num=classes_num, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(img_shape, classes_num, last_activation):\n",
    "    block0_input = Input(shape=(img_shape, img_shape, 3))\n",
    "\n",
    "    block1_conv1 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block0_input)\n",
    "    block1_conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block1_conv1)\n",
    "    block1_conv3 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block1_conv2)\n",
    "    block1_pool1 = MaxPool2D(2)(block1_conv3)\n",
    "\n",
    "    block2_conv1 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block1_pool1)\n",
    "    block2_conv2 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block2_conv1)\n",
    "    block2_conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block2_conv2)\n",
    "    block2_pool1 = MaxPool2D(2)(block2_conv3)\n",
    "\n",
    "    block3_conv1 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block2_pool1)\n",
    "    block3_conv2 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block3_conv1)\n",
    "    block3_conv3 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block3_conv2)\n",
    "    block3_pool1 = MaxPool2D(2)(block3_conv3)\n",
    "\n",
    "    block4_conv1 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(block3_pool1)\n",
    "    block4_conv2 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(block4_conv1)\n",
    "    block4_conv3 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(block4_conv2)\n",
    "    block4_upsa1 = UpSampling2D(2, interpolation=\"bilinear\")(block4_conv3)\n",
    "\n",
    "    block5_conc1 = Concatenate()([block3_conv3, block4_upsa1])\n",
    "    block5_conv1 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block5_conc1)\n",
    "    block5_conv2 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block5_conv1)\n",
    "    block5_conv3 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block5_conv2)\n",
    "    block5_upsa1 = UpSampling2D(2, interpolation=\"bilinear\")(block5_conv3)\n",
    "\n",
    "    block6_conc1 = Concatenate()([block2_conv3, block5_upsa1])\n",
    "    block6_conv1 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block6_conc1)\n",
    "    block6_conv2 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block6_conv1)\n",
    "    block6_conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block6_conv2)\n",
    "    block6_upsa1 = UpSampling2D(2, interpolation=\"bilinear\")(block6_conv3)\n",
    "\n",
    "    block7_conc1 = Concatenate()([block1_conv3, block6_upsa1])\n",
    "    block7_conv1 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block7_conc1)\n",
    "    block7_conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block7_conv1)\n",
    "    block7_conv3 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block7_conv2)\n",
    "\n",
    "    block8_output = Conv2D(classes_num, (1, 1), padding=\"same\", activation=last_activation)(block7_conv3)\n",
    "\n",
    "    return Model(inputs=block0_input, outputs=block8_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(dir_path, callbacks_monitor):\n",
    "    # лучшие веса\n",
    "    best_w_loss = ModelCheckpoint(dir_path + \"best_w_loss.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='auto',\n",
    "                             period=1\n",
    "                             )\n",
    "    \n",
    "    best_w_jaccard = ModelCheckpoint(dir_path + \"best_w_jaccard.h5\",\n",
    "                             monitor=\"val_jaccard_coef\",\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='auto',\n",
    "                             period=1\n",
    "                             )\n",
    "\n",
    "    # последние веса\n",
    "    last_w = ModelCheckpoint(dir_path + \"last_w.h5\",\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True,\n",
    "                             mode='auto',\n",
    "                             period=1\n",
    "                             )\n",
    "\n",
    "    # сохраняет историю обучения\n",
    "    logger = CSVLogger(dir_path + \"logger.csv\",\n",
    "                       append=False)\n",
    "\n",
    "    return [best_w_loss, best_w_jaccard, last_w, logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rv/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if last_activation != 'sigmoid' and last_activation != 'softmax':\n",
    "    raise ValueError(\"Incorrect last activation :\" + last_activation)\n",
    "\n",
    "model = get_model(None, classes_num, last_activation)\n",
    "\n",
    "plot_model(model=model, to_file=callbacks_full_dir + file_name + \".png\", show_shapes=True, dpi=200)\n",
    "\n",
    "if is_load:\n",
    "    if not weight_path:\n",
    "        raise ValueError(\"Don't load weight_path\")\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "if loss_function == 'categorical_crossentropy':\n",
    "    pass\n",
    "elif loss_function == 'dice_loss':\n",
    "    loss_function = dice_loss\n",
    "elif loss_function == 'jaccard_loss':\n",
    "    loss_function = jaccard_loss\n",
    "else:\n",
    "    raise ValueError(\"Incorrect loss function :\" + loss_function)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss=loss_function,\n",
    "              metrics=[\"accuracy\", dice_coef, jaccard_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/rv/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 54s 54s/step - loss: 3.4317 - accuracy: 0.0329 - dice_coef: 0.0607 - jaccard_coef: 0.0313 - val_loss: 3.4263 - val_accuracy: 0.0250 - val_dice_coef: 0.0610 - val_jaccard_coef: 0.0315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fef8748ba90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    epochs=epoch_num,\n",
    "                    steps_per_epoch=int(train_coef * train_size) // batch_size,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_size // batch_size,\n",
    "                    verbose=1,\n",
    "                    callbacks=get_callbacks(callbacks_full_dir, callbacks_monitor)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n",
      "(4, 256, 256, 31)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "val_gen_test = data_gen(img_val_dir, mask_val_dir, classes_num=classes_num, batch_size=batch_size)\n",
    "\n",
    "for (img, mask), i in zip(val_gen_test, range(val_size // batch_size)):\n",
    "    model.predict(img)\n",
    "    \n",
    "stop_time = time.time()\n",
    "\n",
    "sec_on_one_img = (stop_time - start_time)/val_size\n",
    "with open(callbacks_full_dir + \"time.txt\", \"w\") as f:\n",
    "    f.write(str(sec_on_one_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
