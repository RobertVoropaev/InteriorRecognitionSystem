{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка системы распознавания предметов интерьера в потоковом видео\n",
    "## Часть 4: Нейронная сеть для сегментации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#System\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#Base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "#Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Activation, Input\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers import Dropout,BatchNormalization, Concatenate\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "#Preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import Sequence, to_categorical\n",
    "\n",
    "#Models\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#GPU\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "K.set_session(sess)\n",
    "\n",
    "#Seed\n",
    "seed = 99\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Настройки сегментации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим папки с изображениями и масками для обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/ADE20K_encoded/train/\"\n",
    "val_dir = \"data/ADE20K_encoded/val/\"\n",
    "\n",
    "img_train_dir = train_dir + \"img/\"\n",
    "mask_train_dir = train_dir + \"mask/\"\n",
    "\n",
    "img_val_dir = val_dir + \"img/\"\n",
    "mask_val_dir = val_dir + \"mask/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер обучающей и валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6522\n",
      "Val size: 644\n"
     ]
    }
   ],
   "source": [
    "train_size = len(os.listdir(path = train_dir + \"img/\"))\n",
    "val_size = len(os.listdir(path = val_dir + \"img/\"))\n",
    "print(\"Train size: \" + str(train_size))\n",
    "print(\"Val size: \" + str(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроки нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 256\n",
    "batch_size = 4\n",
    "num_classes = 32\n",
    "\n",
    "epoch_num = 50\n",
    "train_coef = 0.1 # доля объектов тренировочной выборки на каждой эпохе\n",
    "learning_rate = 0.0001\n",
    "\n",
    "callbacks_dir_name = \"model00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент Дайса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + smooth) / \n",
    "            (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент Джакарда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred, smooth=1.):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return ((intersection + smooth) / \n",
    "            (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss-функции "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_loss(y_true, y_pred):\n",
    "    return 1 - jaccard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Генератор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(img_dir, mask_dir, num_classes, batch_size):\n",
    "    img_folder = img_dir\n",
    "    mask_folder = mask_dir\n",
    "    num_classes = num_classes\n",
    "    \n",
    "    img_list = os.listdir(img_folder)\n",
    "    random.shuffle(img_list)\n",
    "    img_dir_size = len(img_list)\n",
    "    \n",
    "    for i in range(len(img_list)):\n",
    "        img_list[i] = img_list[i].split(\".\")[0] #отделяем имя от формата\n",
    "        \n",
    "    counter = 0\n",
    "    while (True):\n",
    "        img = np.zeros((batch_size, img_shape, img_shape, 3)).astype('float')\n",
    "        mask = np.zeros((batch_size, img_shape, img_shape, num_classes)).astype(\"uint8\")\n",
    "\n",
    "        for i in range(counter, counter + batch_size):  \n",
    "\n",
    "            train_img = cv2.imread(img_folder + '/' + img_list[i] + \".jpg\") / 255.\n",
    "            train_img =  cv2.resize(train_img, (img_shape, img_shape))\n",
    "\n",
    "            img[i - counter] = train_img \n",
    "\n",
    "            train_mask = cv2.imread(mask_folder + '/' + img_list[i] + \".png\", cv2.IMREAD_GRAYSCALE)\n",
    "            train_mask = cv2.resize(train_mask, (img_shape, img_shape), interpolation = cv2.INTER_NEAREST)\n",
    "            train_mask = train_mask.reshape(img_shape, img_shape, 1)\n",
    "            train_mask = to_categorical(train_mask, num_classes=num_classes)\n",
    "            \n",
    "            mask[i - counter] = train_mask\n",
    "\n",
    "        counter += batch_size\n",
    "        \n",
    "        if (counter + batch_size >= img_dir_size):\n",
    "            counter = 0\n",
    "            random.shuffle(img_list)\n",
    "                  \n",
    "        yield img, mask\n",
    "        \n",
    "train_gen = data_gen(img_train_dir,mask_train_dir, num_classes=num_classes, batch_size=batch_size)\n",
    "val_gen = data_gen(img_val_dir,mask_val_dir, num_classes=num_classes, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rv/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_model(img_shape, num_classes):\n",
    "    block0_input = Input(shape=(img_shape, img_shape, 3))\n",
    "\n",
    "    block1_conv1 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block0_input)\n",
    "    block1_conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block1_conv1)\n",
    "    block1_conv3 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block1_conv2)\n",
    "    block1_pool1 = MaxPool2D(2)(block1_conv3)\n",
    "\n",
    "    block2_conv1 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block1_pool1)\n",
    "    block2_conv2 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block2_conv1)\n",
    "    block2_conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block2_conv2)\n",
    "    block2_pool1 = MaxPool2D(2)(block2_conv3)\n",
    "\n",
    "    block3_conv1 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block2_pool1)\n",
    "    block3_conv2 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block3_conv1)\n",
    "    block3_conv3 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block3_conv2)\n",
    "    block3_pool1 = MaxPool2D(2)(block3_conv3)\n",
    "\n",
    "    block4_conv1 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(block3_pool1)\n",
    "    block4_conv2 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(block4_conv1)\n",
    "    block4_conv3 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(block4_conv2)\n",
    "    block4_upsa1 = UpSampling2D(2, interpolation=\"bilinear\")(block4_conv3)\n",
    "    \n",
    "    block5_conc1 = Concatenate()([block3_conv3, block4_upsa1])\n",
    "    block5_conv1 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block5_conc1)\n",
    "    block5_conv2 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block5_conv1)\n",
    "    block5_conv3 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(block5_conv2)\n",
    "    block5_upsa1 = UpSampling2D(2, interpolation=\"bilinear\")(block5_conv3)\n",
    "\n",
    "    block6_conc1 = Concatenate()([block2_conv3, block5_upsa1])\n",
    "    block6_conv1 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block6_conc1)\n",
    "    block6_conv2 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block6_conv1)\n",
    "    block6_conv3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(block6_conv2)\n",
    "    block6_upsa1 = UpSampling2D(2, interpolation=\"bilinear\")(block6_conv3)\n",
    "\n",
    "    block7_conc1 = Concatenate()([block1_conv3, block6_upsa1])\n",
    "    block7_conv1 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block7_conc1)\n",
    "    block7_conv2 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block7_conv1)\n",
    "    block7_conv3 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(block7_conv2)\n",
    "    \n",
    "    block8_output = Conv2D(num_classes, (1, 1), padding=\"same\", activation=\"sigmoid\")(block7_conv3)\n",
    "\n",
    "    return Model(inputs=block0_input, outputs=block8_output)\n",
    "\n",
    "model = get_model(None, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(dir_name, callbacks_dir=\"checkpoints/\"):\n",
    "    dir_path = callbacks_dir + dir_name  + \"/\"\n",
    "    os.mkdir(dir_path)\n",
    "    \n",
    "    #лучшие веса\n",
    "    best_w = ModelCheckpoint(dir_path + \"best_w.h5\", \n",
    "                             monitor=\"val_loss\",\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1\n",
    "                            )\n",
    "\n",
    "    #последние веса\n",
    "    last_w = ModelCheckpoint(dir_path + \"last_w.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1\n",
    "                            )\n",
    "    \n",
    "    #сохраняет историю обучения\n",
    "    logger = CSVLogger(dir_path + \"logger.csv\",\n",
    "                       append=True)\n",
    "\n",
    "    return [best_w, last_w, logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rv/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 200s 1s/step - loss: 0.9236 - accuracy: 0.2420 - dice_coef: 0.1413 - jaccard_coef: 0.0764 - val_loss: 0.9212 - val_accuracy: 0.1093 - val_dice_coef: 0.1619 - val_jaccard_coef: 0.0881\n",
      "Epoch 2/50\n",
      "  4/163 [..............................] - ETA: 2:09 - loss: 0.9074 - accuracy: 0.2082 - dice_coef: 0.1695 - jaccard_coef: 0.0926"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "              loss=jaccard_loss, \n",
    "              metrics=[\"accuracy\", dice_coef, jaccard_coef])\n",
    "    \n",
    "model.fit_generator(train_gen, \n",
    "                    epochs=epoch_num,\n",
    "                    steps_per_epoch=int(train_coef*train_size)//batch_size,\n",
    "                    validation_data=val_gen, \n",
    "                    validation_steps=val_size//batch_size,\n",
    "                    verbose=1,\n",
    "                    callbacks=get_callbacks(callbacks_dir_name)\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
